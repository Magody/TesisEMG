El 12 parece tener buenas proyecciones
Experimento 11 es exitoso, subir épocas y reducir repeticiones ayudó, subir batch size también

nota:  16 filtros bien, 32 mucho, bajó
usar convolución [1, 9] en lugar 1,3 bajó mucho el rendimiento
si al inicio hay n canales, al poner un número menor a n como filtro inicial baja el acc un poco


A ciertas horas el RNG no vale y da peores resultados


*****Test with 1 users, each one with 15 gestures*****
Test: Mean collected reward 26.6667
Test: Mean accuracy for classification window: 0.6933
Test: Mean accuracy for classification class: 0.6000

stride muy pequeño no ayuda mucho y alenta

*****Test with 1 users, each one with 15 gestures*****
Test: Mean collected reward 8.7333
Test: Mean accuracy for classification window: 0.6818
Test: Mean accuracy for classification class: 0.5333

window 250 same down

*****Test with 1 users, each one with 15 gestures*****
Test: Mean collected reward 10.0000
Test: Mean accuracy for classification window: 0.6923
Test: Mean accuracy for classification class: 0.3333

baja mucho clasificación
fprintf("Setting hyper parameters and models\n");
generate_rng(seed_rng);
context('interval_for_learning') = 3;  % in each episode will learn this n times more or less
window_size = 200;
stride = 30;

%{
use_channels = false;
height = 10;
context("image_config") = struct("width", 1000, "height", height, "merge", ~use_channels);

shape_input = [height, window_size, 1];  % shape_input = [1, window_size, 8];
if use_channels
    shape_input = [height, window_size, 8];
end
%}
shape_input = [1, window_size, 8];

total_episodes = RepTraining * num_users;
total_episodes_test = RepTesting * num_users_test;
epochs = 1; % epochs inside each NN
learning_rate = 0.001;
batch_size = 64;
gamma = 0.1;
epsilon = 1;
decay_rate_alpha = 0.1;
gameReplayStrategy = 1;
experience_replay_reserved_space = 20;
loss_type = "mse";
rewards = struct('correct', 1, 'incorrect', -1);

context('window_size') = window_size;
context('stride') = stride;
context('rewards') = rewards;
assignin('base','WindowsSize',  window_size);
assignin('base','Stride',  stride);

context('orientation') = orientation;
context('dataPacket') = dataPacket;


sequential_conv_network = Sequential({
    Convolutional([1, 3], 8, 0, 1, shape_input), ...
    Activation("relu"), ....
    Pooling("max", [1, 2]), ...
    Reshape(), ...
});

input_dense = prod(sequential_conv_network.shape_output);% if convolutional network exist, sequential_conv_network.shape_output;

sequential_network = Sequential({
    Dense(64, "kaiming", input_dense), ...
    Activation("relu"), ...
    Dense(64, "kaiming"), ...
    Activation("relu"), ...
    Dense(6, "xavier"), ...
});

nnConfig = NNConfig(epochs, learning_rate, batch_size, loss_type);
nnConfig.decay_rate_alpha = decay_rate_alpha;

qLearningConfig = QLearningConfig(gamma, epsilon, gameReplayStrategy, experience_replay_reserved_space, total_episodes);
qLearningConfig.total_episodes_test = total_episodes_test;
q_neural_network = QNeuralNetwork(sequential_conv_network, sequential_network, ...
                    nnConfig, qLearningConfig, @executeEpisodeEMG);    % @executeEpisodeEMGImage 

q_neural_network.setCustomRunEpisodes(@customRunEpisodesEMG);


*****Test with 1 users, each one with 15 gestures*****
Test: Mean collected reward 9.0000
Test: Mean accuracy for classification window: 0.6957
Test: Mean accuracy for classification class: 0.6000



fprintf("Setting hyper parameters and models\n");
generate_rng(seed_rng);
context('interval_for_learning') = 3;  % in each episode will learn this n times more or less
window_size = 300;
stride = 30;

%{
use_channels = false;
height = 10;
context("image_config") = struct("width", 1000, "height", height, "merge", ~use_channels);

shape_input = [height, window_size, 1];  % shape_input = [1, window_size, 8];
if use_channels
    shape_input = [height, window_size, 8];
end
%}
shape_input = [1, window_size, 8];

total_episodes = RepTraining * num_users;
total_episodes_test = RepTesting * num_users_test;
epochs = 1; % epochs inside each NN
learning_rate = 0.001;
batch_size = 64;
gamma = 0;
epsilon = 1;
decay_rate_alpha = 0.1;
experience_replay_reserved_space = 20;
gameReplayStrategy = 1;
loss_type = "mse";
rewards = struct('correct', 1, 'incorrect', -1);

context('window_size') = window_size;
context('stride') = stride;
context('rewards') = rewards;
assignin('base','WindowsSize',  window_size);
assignin('base','Stride',  stride);

context('orientation') = orientation;
context('dataPacket') = dataPacket;


sequential_conv_network = Sequential({
    Convolutional([1, 3], 8, 0, 1, shape_input), ...
    Activation("relu"), ....
    Pooling("max", [1, 2]), ...
    Reshape(), ...
});

input_dense = prod(sequential_conv_network.shape_output);% if convolutional network exist, sequential_conv_network.shape_output;

sequential_network = Sequential({
    Dense(64, "kaiming", input_dense), ...
    Activation("relu"), ...
    Dense(64, "kaiming"), ...
    Activation("relu"), ...
    Dense(6, "xavier"), ...
});

nnConfig = NNConfig(epochs, learning_rate, batch_size, loss_type);
nnConfig.decay_rate_alpha = decay_rate_alpha;

qLearningConfig = QLearningConfig(gamma, epsilon, gameReplayStrategy, experience_replay_reserved_space, total_episodes);
qLearningConfig.total_episodes_test = total_episodes_test;
q_neural_network = QNeuralNetwork(sequential_conv_network, sequential_network, ...
                    nnConfig, qLearningConfig, @executeEpisodeEMG);    % @executeEpisodeEMGImage 

q_neural_network.setCustomRunEpisodes(@customRunEpisodesEMG);










*****Test with 1 users, each one with 15 gestures*****
Test: Mean collected reward 6.2000
Test: Mean accuracy for classification window: 0.6348
Test: Mean accuracy for classification class: 0.6667


fprintf("Setting hyper parameters and models\n");
generate_rng(seed_rng);
context('interval_for_learning') = 3;  % in each episode will learn this n times more or less
window_size = 300;
stride = 30;

%{
use_channels = false;
height = 10;
context("image_config") = struct("width", 1000, "height", height, "merge", ~use_channels);

shape_input = [height, window_size, 1];  % shape_input = [1, window_size, 8];
if use_channels
    shape_input = [height, window_size, 8];
end
%}
shape_input = [1, window_size, 8];

total_episodes = RepTraining * num_users;
total_episodes_test = RepTesting * num_users_test;
epochs = 1; % epochs inside each NN
learning_rate = 0.001;
batch_size = 64;
gamma = 0.1;
epsilon = 1;
decay_rate_alpha = 0.1;
experience_replay_reserved_space = 20;
gameReplayStrategy = 1;
loss_type = "mse";
rewards = struct('correct', 1, 'incorrect', -1);

context('window_size') = window_size;
context('stride') = stride;
context('rewards') = rewards;
assignin('base','WindowsSize',  window_size);
assignin('base','Stride',  stride);

context('orientation') = orientation;
context('dataPacket') = dataPacket;


sequential_conv_network = Sequential({
    Convolutional([1, 3], 8, 0, 1, shape_input), ...
    Activation("relu"), ....
    Pooling("max", [1, 2]), ...
    Reshape(), ...
});

input_dense = prod(sequential_conv_network.shape_output);% if convolutional network exist, sequential_conv_network.shape_output;

sequential_network = Sequential({
    Dense(64, "kaiming", input_dense), ...
    Activation("relu"), ...
    Dense(64, "kaiming"), ...
    Activation("relu"), ...
    Dense(6, "xavier"), ...
});

nnConfig = NNConfig(epochs, learning_rate, batch_size, loss_type);
nnConfig.decay_rate_alpha = decay_rate_alpha;

qLearningConfig = QLearningConfig(gamma, epsilon, gameReplayStrategy, experience_replay_reserved_space, total_episodes);
qLearningConfig.total_episodes_test = total_episodes_test;
q_neural_network = QNeuralNetwork(sequential_conv_network, sequential_network, ...
                    nnConfig, qLearningConfig, @executeEpisodeEMG);    % @executeEpisodeEMGImage 

q_neural_network.setCustomRunEpisodes(@customRunEpisodesEMG);










Test: Mean collected reward 2.8000
Test: Mean accuracy for classification window: 0.6077
Test: Mean accuracy for classification class: 0.5333


fprintf("Setting hyper parameters and models\n");
generate_rng(seed_rng);
context('interval_for_learning') = 3;  % in each episode will learn this n times more or less
window_size = 300;
stride = 50;

%{
use_channels = false;
height = 10;
context("image_config") = struct("width", 1000, "height", height, "merge", ~use_channels);

shape_input = [height, window_size, 1];  % shape_input = [1, window_size, 8];
if use_channels
    shape_input = [height, window_size, 8];
end
%}
shape_input = [1, window_size, 8];

total_episodes = RepTraining * num_users;
total_episodes_test = RepTesting * num_users_test;
epochs = 1; % epochs inside each NN
learning_rate = 0.001;
batch_size = 64;
gamma = 0.9;
epsilon = 1;
decay_rate_alpha = 0.1;
experience_replay_reserved_space = 20;
gameReplayStrategy = 1;
loss_type = "mse";
rewards = struct('correct', 1, 'incorrect', -1);

context('window_size') = window_size;
context('stride') = stride;
context('rewards') = rewards;
assignin('base','WindowsSize',  window_size);
assignin('base','Stride',  stride);

context('orientation') = orientation;
context('dataPacket') = dataPacket;


sequential_conv_network = Sequential({
    Convolutional([1, 3], 8, 0, 1, shape_input), ...
    Activation("relu"), ....
    Pooling("max", [1, 2]), ...
    Reshape(), ...
});

input_dense = prod(sequential_conv_network.shape_output);% if convolutional network exist, sequential_conv_network.shape_output;

sequential_network = Sequential({
    Dense(64, "kaiming", input_dense), ...
    Activation("relu"), ...
    Dense(64, "kaiming"), ...
    Activation("relu"), ...
    Dense(6, "xavier"), ...
});

nnConfig = NNConfig(epochs, learning_rate, batch_size, loss_type);
nnConfig.decay_rate_alpha = decay_rate_alpha;

qLearningConfig = QLearningConfig(gamma, epsilon, gameReplayStrategy, experience_replay_reserved_space, total_episodes);
qLearningConfig.total_episodes_test = total_episodes_test;
q_neural_network = QNeuralNetwork(sequential_conv_network, sequential_network, ...
                    nnConfig, qLearningConfig, @executeEpisodeEMG);    % @executeEpisodeEMGImage 

q_neural_network.setCustomRunEpisodes(@customRunEpisodesEMG);
